# Pipeline for classification
# Decision Tree and Random Forest

# Load Library
```{r}
library(caret)
```

# Label categorical variables
```{r}
data_customer_segmentation$target_categorical <- factor(data_customer_segmentation$target, levels = 1:0,
                            labels = c("buyer", "non.buyer"))
```

# Classification class distribution in full dataset
```{r}
freq_table <- table(data_customer_segmentation$target_categorical)
cbind(Frequency = freq_table,
      Proportion = round(prop.table(freq_table), 3))
```

# Define train and test sets ----------------------------------------------
```{r}
# Holdout a validation set, by defining the indices of the training set
set.seed(811)
train_index <- createDataPartition(data_customer_segmentation$target_categorical, p = 0.8, list = FALSE)
train_set <- data_customer_segmentation[train_index, ]
test_set  <- data_customer_segmentation[-train_index, ]
```

# Compare Decision Tree vs Random Forest ----------------------------------
# Note 1:
#   To minimize generalization error, run algorithms using
#   3 times 5-fold cross validation.
# Note 2:
#   As performance metric, we'll use the Area Under the ROC curve
#   
# We'll use function trainControl to setup the training parameters
# of the model.
```{r}
metric <- "ROC"
control <- trainControl(method = "repeatedcv",
                        number = 5, # number of folds
                        repeats = 3, # number of repetitions
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE,
                        savePredictions = TRUE)

# Learn Decision Tree (rpart)
set.seed(811)
model_DT <- train(target_categorical ~ monetary_cluster + frequency_cluster + recency_cluster ,
                  data = train_set,
                  method = "rpart", # Decision Trees, with CART algorithm
                  metric = metric,
                  trControl = control)
```

# Check models, metrics and specific tunning parameters
```{r}
#   cp: Complexity parameter
#   mtry: Number of randomly drawn candidate variables
print(model_DT)
print(model_DT$results$cp)
```

# Validate results with a Confusion Matrix --------------------------------
```{r}
# Calculate model predictions on TEST set
prediction_dt_prob <- predict(model_DT, test_set, type = "prob")
test_set$prediction_prob <- prediction_dt_prob
head(prediction_dt_prob)

prediction_dt_raw <- predict(model_DT, test_set, type = "raw")
test_set$prediction_raw <- prediction_dt_raw
head(prediction_dt_raw)
```

# Confusion matrix
```{r}
confusionMatrix(data = prediction_dt_raw,
                reference = test_set$target_categorical)
                # Tip: use the following argument for more metrics
                #   mode = "everything"
                # Note that:
                #   Precison = Pos Pred Value
                #   Recall = Sensitivity
```



