---
title: "Untitled"
author: "Fabian Garrett"
date: "2024-04-09"
output: html_document
---

```{r}
library(caret)
```
# Label categorical variables
```{r}
data_customer_cutoff$target <- factor(data_customer_cutoff$target, levels = 1:0,
                            labels = c("buyer", "non.buyer"))
```
# Classification class distribution in full dataset
```{r}
freq_table <- table(data_customer_cutoff$target)
cbind(Frequency = freq_table,
      Proportion = round(prop.table(freq_table), 3))
```
# Define train and test sets ----------------------------------------------
```{r}
seed <- 541
set.seed(seed)
# Criar índices para divisão do conjunto de dados
train_index <- createDataPartition(data_customer_cutoff$target, p = 0.01, list = FALSE)

# Criar train_set contendo apenas as colunas "customer_unique_id" e "target"
train_set <- data_customer_cutoff[train_index, c("customer_unique_id", "target")]

# Criar test_set contendo apenas as colunas "customer_unique_id" e "target"
test_set <- data_customer_cutoff[-train_index, c("customer_unique_id", "target")]
```
#verify N/A  and exclude
```{r}
any(is.na(train_set))

train_set <- na.omit(train_set)

any(is.na(train_set))
```

# metric roc
```{r}
metric <- "ROC"
control <- trainControl(method = "repeatedcv",
                        number = 5, # number of folds
                        repeats = 3, # number of repetitions
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE,
                        savePredictions = TRUE)
```
# Learn Decision Tree (rpart)
```{r}
# Treinando o modelo de árvore de decisão novamente
set.seed(seed)
model_DT <- train(target ~ .,
                  data = train_set,
                  method = "rpart", # Decision Trees, with CART algorithm
                  metric = metric,
                  trControl = control)
```
# Learn Random Forest (rf)
```{r}
set.seed(seed)
model_RF <- train(target ~ .,
                  data = train_set,
                  method = "rf",  # Random Forests
                  metric = metric,
                  trControl = control)
```
#' Check models, metrics and specific tunning parameters
#'   cp: Complexity parameter
#'   mtry: Number of randomly drawn candidate variables
```{r}
print(model_DT)
```
```{r}
print(model_RF)
```
#' Calculate and compare models' performance
#' Note:
#'   - We'll use function 'resamples()' for visualization
#'     of the resampling results
#'   - These calculations are based on resampling the TRAIN set

```{r}
fit_models <- list(Decision_tree = model_DT, 
                   Random_forest = model_RF)
results <- resamples(fit_models) 
dotplot(results)
summary(results)
```
# Check Complexity Parameter (cp) used for trained model
```{r}
print(model_DT$results$cp)
```
# Plot ROC vs Complexity Parameter for model
```{r}
plot(model_DT, main = "Decision Tree")
```
# Check mtry parameter used for trained model
# getModelInfo(model_RF)$rf$parameters
```{r}
print(model_RF$results$mtry)
```
#Plot ROC vs used parameters for model
```{r}
plot(model_RF, main = "Random Forest")
```

# Improve the Random Forest model -----------------------------------------
# To improve the RF model, we fine tune the mtry parameter
```{r}
tune_grid <- expand.grid(mtry = 1:10)

set.seed(seed)
model_RF_tuned <- train(target ~ .,
                       data = train_set,
                       method = "rf",
                       metric = metric,
                       trControl = control,
                       tuneGrid = tune_grid)
```
# Inspect model
```{r}
print(model_RF_tuned)
```
# Plot ROC vs used parameters
```{r}
plot(model_RF_tuned,
     main = "Random Forest - tuned for mtry parameter")
```
# Compare all models ------------------------------------------------------
# Calculate and compare models' performance
```{r}
it_models <- list(Decision_tree = model_DT, 
                   Random_forest = model_RF,
                   Random_forest_tuned = model_RF_tuned)
results <- resamples(fit_models)
dotplot(results)
summary(results)
```
# Model Validation --------------------------------------------------------
#' To validate the model, we'll make predictions from the TEST set
# Estimate performance of Random Forest on the TEST dataset
```{r}
predictions_prob <- predict(model_RF_tuned, test_set, type = "prob")
head(predictions_prob)
predictions_raw <- predict(model_RF_tuned, test_set, type = "raw")
head(cbind(predictions_prob, predictions_raw))
```
# Confusion Matrix
```{r}
confusionMatrix(data = predictions_raw,
                reference = test_set$target)
```


